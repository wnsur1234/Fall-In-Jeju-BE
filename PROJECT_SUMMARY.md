# 🚀 4-in-Jeju 백엔드 프로젝트: CI/CD 및 Dev/Prod 환경 구축 완전 정복 가이드

안녕하세요! 이 가이드는 '4-in-Jeju' 백엔드 프로젝트를 진행하면서 우리가 함께 구축한 **CI/CD (지속적 통합/지속적 배포) 파이프라인**과 **개발(Dev)/운영(Prod) 환경 분리** 과정을 처음부터 끝까지 상세하게 설명해 드립니다. AWS와 Kubernetes가 처음이신 분들도 쉽게 이해할 수 있도록 비유와 그림을 곁들여 설명할 예정이니, 걱정 마시고 천천히 따라와 주세요!

---

## 🌟 프로젝트 목표: 왜 이런 복잡한 것을 만들었을까요?

우리의 최종 목표는 **안정적이고 효율적인 백엔드 서비스 배포 시스템**을 만드는 것이었습니다.

**주요 목표:**
1.  **자동화된 배포**: 개발자가 코드를 작성하여 GitHub에 올리기만 하면, 나머지는 시스템이 알아서 빌드하고 배포하도록 합니다. (수동 작업 최소화)
2.  **안정적인 서비스 운영**: 개발 중인 코드와 실제 사용자에게 제공되는 코드를 명확히 분리하여, 개발 과정의 실수가 운영 서비스에 영향을 주지 않도록 합니다.
3.  **쉬운 확장 및 관리**: 갑자기 사용자가 많아지더라도 쉽게 서버를 늘리고 줄일 수 있으며, 문제가 발생했을 때 빠르게 원인을 찾고 해결할 수 있도록 합니다.
4.  **안전한 통신**: 웹사이트와 사용자 간의 통신을 암호화하여 중요한 정보가 유출되지 않도록 합니다 (HTTPS).

---

## 🌈 전체 시스템 아키텍처 (대략적인 그림)

```
[개발자] ---(코드 푸시)---> [GitHub]
    |                         ^
    |                         | (GitOps: 상태 동기화)
    v                         |
[AWS CodeBuild] ---(Docker 이미지 빌드)---> [AWS ECR]
    |                                            |
    v                                            | (이미지 가져오기)
[ArgoCD] <------------------------------------- [AWS EKS 클러스터]
    |                                                 ^
    |                                                 |
    v                                                 |
[Kubernetes Manifests (Kustomize)] --(Ingress, Service, Pod)---> [AWS ALB] ---(HTTPS)---> [Route53 (도메인)]
    (Dev/Prod Overlay)                                 ^           ^
                                                       |           |
                                                       (ALB Controller)
```

---

## 🛠️ 사용된 주요 기술 스택과 그 역할 (핵심 구성 요소)

우리가 사용한 AWS 서비스들과 Kubernetes 구성 요소들이 어떤 역할을 하는지 비유를 들어 설명해 드릴게요.

### 🌎 AWS 클라우드 서비스 (Cloud Services)

*   **AWS EKS (Elastic Kubernetes Service)**
    *   **비유**: 여러 대의 컴퓨터(서버)를 직접 관리하지 않고, AWS가 알아서 관리해 주는 **컨테이너화된 애플리케이션의 '놀이터'이자 '지휘 센터'**입니다. 우리 백엔드 애플리케이션은 이 위에서 컨테이너 형태로 실행됩니다.
    *   **핵심 역할**: 우리 백엔드 애플리케이션(컨테이너)들을 배포, 확장, 관리해주는 기반 환경을 제공합니다.
    *   **왜 필요한가요?**: 애플리케이션이 갑자기 트래픽이 몰려도 자동으로 서버를 늘려주고, 문제가 생기면 다른 서버로 옮겨주는 등 복잡한 서버 관리를 AWS가 대신 해주기 때문입니다.
    *   **기대 효과**: 서버 관리 부담 감소, 애플리케이션의 안정성 및 확장성 향상.

*   **AWS CodeBuild (CI)**
    *   **비유**: 개발자가 코드를 주면 자동으로 요리(빌드)하고 예쁜 그릇에 담아(Docker 이미지 생성) 냉장고(ECR)에 넣어주는 **자동 요리 로봇**입니다.
    *   **핵심 역할**: GitHub에 코드가 푸시되면 자동으로 코드를 빌드하고, 테스트를 수행하며, Docker 이미지를 생성하여 ECR에 저장합니다.
    *   **왜 필요한가요?**: 개발자가 매번 수동으로 빌드하고 이미지를 만드는 것은 번거롭고 실수할 수 있습니다. CodeBuild는 이 과정을 자동화하여 개발 생산성을 높입니다.
    *   **기대 효과**: 빌드 과정 자동화, 개발 시간 단축, 빌드 오류 감소.

*   **AWS ECR (Elastic Container Registry)**
    *   **비유**: CodeBuild가 만든 Docker 이미지를 안전하게 보관하는 **이미지 냉장고 (중앙 저장소)**입니다.
    *   **핵심 역할**: 우리 애플리케이션의 Docker 이미지들을 저장하고 관리합니다. EKS 클러스터는 이곳에서 이미지를 가져와 애플리케이션을 실행합니다.
    *   **왜 필요한가요?**: Docker 이미지를 안전하고 효율적으로 저장하고 관리할 중앙 저장소가 필요합니다. ECR은 AWS의 완전 관리형 컨테이너 이미지 레지스트리로, EKS가 쉽게 접근할 수 있습니다.
    *   **기대 효과**: Docker 이미지의 안전한 저장 및 버전 관리, EKS와의 쉬운 연동.

*   **AWS ALB (Application Load Balancer)**
    *   **비유**: 우리 식당(애플리케이션)으로 오는 손님(웹 트래픽)을 여러 개의 주방(애플리케이션 Pod)으로 골고루 분산시켜주는 **스마트 교통 정리 경찰**입니다.
    *   **핵심 역할**: 외부에서 들어오는 웹 트래픽을 EKS 클러스터 내부의 여러 애플리케이션 인스턴스(Pod)로 분산시켜줍니다. HTTPS(암호화 통신) 처리도 해줍니다.
    *   **왜 필요한가요?**: 트래픽이 많을 때 특정 서버에 부하가 집중되는 것을 막고, 애플리케이션의 안정성과 성능을 유지하기 위함입니다.
    *   **기대 효과**: 트래픽 분산, 서비스 안정성 향상, HTTPS 적용.

*   **AWS ACM (Certificate Manager)**
    *   **비유**: 우리 웹사이트의 **안전 보증서 (SSL/TLS 인증서)**를 발급하고 관리해주는 기관입니다.
    *   **핵심 역할**: 웹사이트의 HTTPS 통신을 위한 SSL/TLS 인증서를 발급하고 갱신해줍니다.
    *   **왜 필요한가요?**: 웹사이트와 사용자 간의 통신을 암호화하여 정보를 안전하게 보호하기 위함입니다. `https://` 주소를 사용하려면 이 인증서가 필수입니다.
    *   **기대 효과**: 웹사이트 보안 강화, 사용자 신뢰도 증가.

*   **AWS Route53**
    *   **비유**: 웹사이트 주소(도메인)와 서버의 실제 주소(IP 또는 ALB 주소)를 연결해주는 **인터넷 전화번호부**입니다.
    *   **핵심 역할**: `api.fall-in-jeju.com`과 같은 도메인 이름을 사용자가 입력했을 때, 실제 서비스가 실행 중인 ALB의 주소를 찾아 연결해줍니다.
    *   **왜 필요한가요?**: 사용자가 복잡한 IP 주소 대신 기억하기 쉬운 도메인 이름으로 서비스에 접근할 수 있도록 해주어야 합니다.
    *   **기대 효과**: 편리한 도메인 관리, 서비스 접근성 향상.

*   **AWS RDS (Relational Database Service)**
    *   **비유**: 우리 애플리케이션의 데이터를 저장하는 **관리형 데이터베이스 서버**입니다.
    *   **핵심 역할**: MySQL과 같은 관계형 데이터베이스를 AWS가 대신 설치하고 관리해줍니다. 우리는 데이터베이스 서버를 직접 운영하는 복잡성 없이 데이터만 저장하고 가져올 수 있습니다.
    *   **왜 필요한가요?**: 데이터베이스 서버 운영은 백업, 업데이트, 장애 처리 등 매우 복잡합니다. RDS는 이러한 작업을 AWS가 대신 해주므로 우리는 애플리케이션 개발에만 집중할 수 있습니다.
    *   **기대 효과**: 데이터베이스 운영 부담 감소, 높은 안정성과 확장성.

*   **AWS DynamoDB**
    *   **비유**: 유연하고 매우 빠르게 데이터를 저장하고 꺼낼 수 있는 **초고속 특수 데이터 창고**입니다.
    *   **핵심 역할**: 정해진 형식 없이 자유롭게 데이터를 저장하고, 매우 빠른 속도로 데이터를 처리할 수 있는 NoSQL 데이터베이스입니다. 채팅 기록, 실시간 랭킹 등 빠르게 변화하고 대규모의 데이터에 적합합니다.
    *   **왜 필요한가요?**: 관계형 DB로는 비효율적인 특정 유형의 데이터 처리나 대규모 트래픽 처리에 특화되어 있습니다.
    *   **기대 효과**: 초고속 데이터 처리, 대규모 트래픽에 대한 확장성, 관리 용이성.

### 📦 Kubernetes 구성 요소 (Components)

*   **Kubernetes (K8s)**
    *   **비유**: 여러 대의 컴퓨터(서버) 위에서 우리 애플리케이션을 담은 컨테이너들을 마치 **지휘자처럼 관리**해주는 똑똑한 시스템입니다.
    *   **핵심 역할**: 컨테이너화된 애플리케이션을 자동으로 배포, 확장, 관리해주는 오픈소스 플랫폼입니다. AWS EKS는 이 Kubernetes를 AWS 환경에서 쉽게 사용할 수 있도록 해주는 서비스입니다.
    *   **왜 필요한가요?**: 수많은 컨테이너들을 수동으로 관리하는 것은 불가능합니다. Kubernetes는 이 모든 과정을 자동화하여 효율적으로 운영할 수 있도록 합니다.
    *   **기대 효과**: 애플리케이션 배포 및 운영 자동화, 높은 확장성과 안정성.

*   **Pod**
    *   **비유**: 컨테이너화된 우리 애플리케이션을 담는 **가장 작은 단위의 '집' 또는 '캡슐'**입니다. Pod 안에는 하나 이상의 컨테이너가 들어갈 수 있습니다.
    *   **핵심 역할**: 우리 백엔드 애플리케이션의 Docker 이미지가 Pod 안에서 실행됩니다.
    *   **왜 필요한가요?**: 컨테이너를 직접 관리하는 대신 Pod라는 추상화된 단위로 관리하면, 컨테이너들이 함께 작동하고 통신하는 방식을 더 쉽게 정의할 수 있습니다.
    *   **기대 효과**: 컨테이너 관리의 용이성, 컨테이너 간의 네트워크 및 스토리지 공유.

*   **Deployment**
    *   **비유**: 우리 애플리케이션 Pod를 몇 개 만들고(복제본 수), 어떻게 업데이트할지 알려주는 **배포 지침서**입니다.
    *   **핵심 역할**: 특정 애플리케이션 Pod를 몇 개 유지할 것인지, 새로운 버전으로 업데이트할 때는 어떻게 점진적으로 적용할 것인지 등을 정의합니다.
    *   **왜 필요한가요?**: 애플리케이션의 안정적인 운영을 위해 항상 일정 수 이상의 Pod가 실행되어야 하며, 업데이트 시에도 서비스 중단 없이 안전하게 전환해야 합니다.
    *   **기대 효과**: 자동 복제 및 스케일링, 무중단 업데이트, 쉬운 롤백.

*   **Service**
    *   **비유**: Pod들이 죽거나 새로 생겨도 항상 고정된 주소를 제공하는 **애플리케이션의 고정 간판**입니다.
    *   **핵심 역할**: 여러 Pod를 하나의 논리적인 서비스로 묶어주고, 이 서비스에 고정된 네트워크 주소를 부여합니다. 외부 또는 다른 서비스들이 이 고정 주소를 통해 Pod에 접근할 수 있도록 합니다.
    *   **왜 필요한가요?**: Pod는 생성될 때마다 IP 주소가 바뀌기 때문에, 고정된 주소 없이는 다른 서비스가 Pod에 접근하기 어렵습니다. Service가 이 문제를 해결해 줍니다.
    *   **기대 효과**: Pod의 동적인 변화에 상관없이 안정적인 접근점 제공, 서비스 간의 디스커버리.

*   **Ingress**
    *   **비유**: 외부에서 우리 식당(애플리케이션)으로 들어오는 손님(트래픽)을 어디로 안내할지 정해주는 **외부 출입문 규칙서**입니다.
    *   **핵심 역할**: 외부 트래픽(HTTP/HTTPS)을 클러스터 내부의 특정 Service로 라우팅하는 규칙을 정의합니다. (AWS 환경에서는 AWS ALB Controller가 Ingress 규칙을 보고 ALB를 생성합니다.)
    *   **왜 필요한가요?**: 여러 애플리케이션이 하나의 도메인을 공유하거나, 특정 경로로 들어오는 트래픽을 다른 서비스로 보내야 할 때 유용합니다.
    *   **기대 효과**: 유연한 트래픽 라우팅, 단일 로드 밸런서로 여러 서비스 노출.

*   **IngressClass**
    *   **비유**: 여러 종류의 "외부 출입문 규칙서" 중에서 우리가 **어떤 종류의 출입문 규칙서를 사용할지 지정**하는 것입니다.
    *   **핵심 역할**: 어떤 Ingress Controller(예: AWS ALB Controller)가 특정 Ingress 리소스를 처리할지 명시적으로 알려줍니다.
    *   **왜 필요한가요?**: 클러스터 내에 여러 종류의 Ingress Controller가 설치될 수 있으므로, 어떤 Controller가 우리 Ingress를 관리할지 명확히 해야 합니다.
    *   **기대 효과**: Ingress Controller 선택의 유연성, 충돌 방지.

*   **Secret**
    *   **비유**: 데이터베이스 비밀번호, API 키 등 **중요한 비밀 정보를 담는 금고**입니다.
    *   **핵심 역할**: 애플리케이션에 필요한 민감한 데이터(비밀번호, 토큰 등)를 안전하게 저장하고, Pod에 환경 변수나 파일 형태로 주입할 수 있도록 합니다.
    *   **왜 필요한가요?**: 코드나 Manifest 파일에 비밀 정보를 직접 노출하는 것을 방지하여 보안을 강화하기 위함입니다.
    *   **기대 효과**: 민감 정보의 안전한 관리, 코드와 설정의 분리.

*   **Namespace**
    *   **비유**: 하나의 Kubernetes 클러스터 안에 여러 개의 **독립된 가상 공간**을 만드는 것입니다.
    *   **핵심 역할**: EKS 클러스터 내부에서 리소스(Pod, Service, Ingress 등)를 논리적으로 격리하는 데 사용됩니다. `dev` 환경과 `prod` 환경의 리소스를 서로 분리할 때 사용했습니다.
    *   **왜 필요한가요?**: 개발 환경과 운영 환경의 리소스가 서로 간섭하지 않도록 분리하여 관리하기 위함입니다.
    *   **기대 효과**: 리소스 관리의 용이성, 환경 간의 독립성 보장, 보안 강화.

*   **Kustomize**
    *   **비유**: `base` 레고 블록으로 기본 집을 만들고, `overlays` 레고 블록으로 개발용 지붕이나 운영용 지붕을 바꿔 끼우는 **레고 조립 가이드**입니다.
    *   **핵심 역할**: Kubernetes Manifest 파일들의 공통 부분(`base`)과 환경별 다른 부분(`overlays`)을 분리하여 관리할 수 있게 해주는 도구입니다.
    *   **왜 필요한가요?**: 개발 환경, 운영 환경 등 여러 환경에 배포할 때, 대부분의 설정은 같고 일부만 다를 수 있습니다. Kustomize는 이런 중복을 줄이고 환경별 차이점만 효율적으로 관리하게 해줍니다.
    *   **기대 효과**: Manifest 파일 관리의 효율성 증대, 환경별 설정 적용 용이.

*   **ArgoCD (CD)**
    *   **비유**: GitHub 저장소의 설계도(Manifest 파일)를 보고, EKS 클러스터에 건물을 짓고(배포), 항상 설계도대로 지어져 있는지 확인하는 **자동 건설 현장 감독**입니다.
    *   **핵심 역할**: Git 저장소에 있는 Kubernetes Manifest 파일을 기반으로 EKS 클러스터에 애플리케이션을 자동으로 배포하고, 클러스터의 실제 상태가 Git의 상태와 일치하는지 지속적으로 모니터링합니다.
    *   **왜 필요한가요?**: 수동 배포의 번거로움과 오류를 줄이고, Git을 통해 모든 배포 상태를 관리하여 "코드형 인프라(Infrastructure as Code)"를 실현하기 위함입니다.
    *   **기대 효과**: 배포 자동화, 높은 신뢰성, 빠른 장애 복구, 환경 간 일관성 유지.

---

## 🗺️ 지금까지의 여정: 우리가 무엇을 했고, 왜 그렇게 했을까요? (단계별 적용 내용 및 이유)

우리는 다음과 같은 과정을 거쳐 백엔드 CI/CD 파이프라인과 Dev/Prod 환경을 구축했습니다.

### **1단계: Kubernetes Manifest 파일 구조화 (Kustomize 도입)**

*   **적용 내용**: 기존의 단일 Kubernetes Manifest 파일을 `k8s-manifests/base`와 `k8s-manifests/overlays/dev`, `k8s-manifests/overlays/prod` 디렉토리로 나누었습니다.
    *   `base`에는 `deployment.yml`, `service.yml`, `ingress.yml`처럼 개발/운영 환경에서 공통으로 사용될 기본적인 정의를 넣었습니다.
    *   `overlays/dev`와 `overlays/prod`에는 각 환경에 특화된 설정(예: `replicas` 개수, `SPRING_PROFILES_ACTIVE` 값, `Ingress`의 `host` 이름 등)을 `patch` 파일 형태로 정의했습니다.
*   **적용 이유**:
    *   **환경 분리**: 개발 환경(Dev)과 운영 환경(Prod)은 리소스 사용량, DB 연결, 도메인 이름 등 많은 부분이 다릅니다. Kustomize를 사용하면 공통된 부분을 `base`로 관리하고, 환경별 차이점만 `overlays`에서 '패치'하듯이 적용할 수 있어 효율적입니다.
    *   **코드 중복 제거**: 공통 설정을 반복해서 작성할 필요 없이 `base`를 재사용함으로써 코드 중복을 줄였습니다.
    *   **가독성 및 관리 용이성**: 환경별 설정이 한눈에 들어와 어떤 부분이 다른지 쉽게 파악하고 관리할 수 있습니다.

### **2단계: AWS CodeBuild (CI) 설정 업데이트**

*   **적용 내용**: `buildspec.yml` 파일을 수정하여, Kubernetes Manifest 파일 구조 변경에 대응하고, 빌드된 Docker 이미지를 ECR에 푸시하도록 했습니다.
    *   또한, Spring Boot 애플리케이션의 Health Check를 위해 `spring-boot-starter-actuator` 의존성을 추가했습니다.
*   **적용 이유**:
    *   **새로운 Manifest 구조 반영**: Kustomize를 도입했기 때문에, CodeBuild가 빌드 후 Manifest 파일을 ECR 이미지 태그로 업데이트할 때 올바른 경로(예: `k8s-manifests/base/deployment.yml`)를 참조하도록 변경했습니다.
    *   **애플리케이션 Health Check**: Kubernetes가 Pod의 상태를 정확하게 판단하고 비정상 Pod를 자동으로 재시작할 수 있도록, Spring Boot Actuator를 통해 `/actuator/health` 엔드포인트를 제공하도록 했습니다. 이는 서비스의 안정성에 매우 중요합니다.

### **3단계: ArgoCD (CD) 애플리케이션 생성 및 설정**

*   **적용 내용**: `backend-dev`와 `backend-prod`라는 두 개의 ArgoCD 애플리케이션을 생성했습니다.
    *   `backend-dev`는 `k8s-manifests/overlays/dev` 경로를 모니터링하고 `dev` 네임스페이스에 배포하도록 했습니다.
    *   `backend-prod`는 `k8s-manifests/overlays/prod` 경로를 모니터링하고 `prod` 네임스페이스에 배포하도록 했습니다.
    *   로컬에서 ArgoCD UI에 접속하기 위해 `kubectl port-forward` 명령어를 사용했습니다.
*   **적용 이유**:
    *   **GitOps 원칙 구현**: Git 저장소의 Manifest 파일이 "진리의 원천"이 되어, 클러스터의 실제 상태를 항상 Git과 일치시키도록 합니다. 이는 배포의 안정성과 투명성을 높입니다.
    *   **자동 배포**: GitHub에 코드가 변경되면 ArgoCD가 이를 감지하고 자동으로 EKS 클러스터에 배포합니다.
    *   **Rollback 용이성**: 문제가 발생하면 Git의 이전 커밋으로 되돌리는 것만으로도 이전 버전으로 쉽게 롤백할 수 있습니다.
    *   **가시성**: ArgoCD UI를 통해 배포된 애플리케이션의 상태, 로그, 이벤트 등을 한눈에 확인할 수 있습니다.

### **4단계: Kubernetes Namespace 및 Secret 설정**

*   **적용 내용**:
    *   EKS 클러스터에 `dev`와 `prod` 네임스페이스를 생성했습니다.
    *   민감한 DB 연결 정보(URL, 사용자 이름, 비밀번호)와 AWS DynamoDB 인증 정보(Access Key, Secret Key, Region)를 Kubernetes Secret(`mysql-credentials`, `dynamodb-credentials`)으로 생성했습니다.
    *   `deployment.yml`에서 `envFrom` 기능을 사용하여 이 Secret 값들을 Pod의 환경 변수로 주입하도록 했습니다.
*   **적용 이유**:
    *   **리소스 격리**: `dev`와 `prod` 네임스페이스를 통해 각 환경의 리소스들이 서로 영향을 주지 않고 독립적으로 운영되도록 합니다.
    *   **보안 강화**: DB 비밀번호나 AWS 인증 정보 같은 민감한 데이터를 Manifest 파일에 직접 노출하는 것은 매우 위험합니다. Secret을 사용하면 이를 안전하게 암호화하여 저장하고 필요한 Pod에만 제공할 수 있습니다.
    *   **환경 변수 관리 효율성**: `envFrom`을 사용하면 Secret의 모든 키-값 쌍이 자동으로 환경 변수로 주입되므로, `deployment.yml`을 깔끔하게 유지할 수 있습니다. (이전 `application-dev.yml`에서 `DATASOURCE_URL` 등에 직접 `${}` 플레이스홀더를 사용했을 때 발생했던 순환 참조 에러를 해결하는 데도 도움이 되었습니다.)

### **5단계: AWS Load Balancer Controller 설치 및 Ingress 설정**

*   **적용 내용**:
    *   EKS 클러스터에 AWS Load Balancer Controller를 Helm 차트를 통해 설치했습니다. (ArgoCD 앱으로 등록)
    *   ALB Controller가 AWS 리소스에 접근할 수 있도록 IAM OIDC Provider를 EKS 클러스터와 연동했습니다.
    *   `k8s-manifests/base/ingress-class.yml` 파일을 생성하여 `alb` IngressClass를 명시적으로 정의했습니다.
    *   `k8s-manifests/base/ingress.yml` 파일에 공통적인 ALB 설정(예: `scheme: internet-facing`, `listen-ports`, `healthcheck-path`)과 **ACM 인증서 ARN을 직접 명시**했습니다.
    *   `k8s-manifests/overlays/dev/ingress-patch.yml`와 `k8s-manifests/overlays/prod/ingress-patch.yml`에서는 `host` 이름(`dev-api.fall-in-jeju.com`, `api.fall-in-jeju.com`)과 `group.name`만 설정하도록 변경하여, ACM ARN은 `base`에서 상속받도록 했습니다.
*   **적용 이유**:
    *   **외부 접근 활성화**: Kubernetes Ingress를 통해 외부 인터넷에서 백엔드 애플리케이션에 접속할 수 있도록 AWS ALB를 자동으로 프로비저닝하기 위함입니다.
    *   **HTTPS 통신**: ACM에서 발급받은 SSL/TLS 인증서를 ALB에 연결하여, 사용자-ALB 구간의 통신을 암호화하고 보안을 강화합니다.
    *   **IngressClass 명시**: 클러스터에 여러 Ingress Controller가 있을 수 있으므로, 우리가 AWS ALB Controller를 사용하고 있음을 명확히 지정하여 올바른 Controller가 Ingress 리소스를 처리하도록 합니다.
    *   **Kustomize 효율성**: ACM ARN은 모든 환경에서 동일한 와일드카드 인증서를 사용하므로 `base`에 두는 것이 가장 효율적입니다. 이렇게 하면 각 `overlay`에서는 `host` 이름만 관리하면 됩니다. (이전에 `dev` Ingress에서 `ValidationError: A certificate must be specified` 에러가 발생했던 주요 원인을 해결했습니다.)

### **6단계: Spring Boot 애플리케이션 설정 파일 정리 (Bedrock 비활성화)**

*   **적용 내용**:
    *   `src/main/resources/application-dev.yml`, `src/main/resources/application-prod.yml`, `src/main/resources/application-local.yml` 파일에서 Bedrock 관련 설정들을 모두 **완전히 삭제**하거나 주석 처리했습니다.
    *   `src/main/java/com/jeju/ormicamp/common/config/AwsProdConfig.java`와 `src/main/java/com/jeju/ormicamp/common/config/bedrock/AwsProperties.java` 파일에서도 Bedrock 관련 코드(특히 `@Value` 어노테이션이 붙은 필드나 빈 정의)를 **완전히 삭제**했습니다.
*   **적용 이유**:
    *   **애플리케이션 시작 오류 방지**: Bedrock 관련 서비스 설정이 아직 완료되지 않은 상태에서 애플리케이션이 시작될 때, 필요한 환경 변수(플레이스홀더)를 찾지 못해 `BeanCreationException` 에러가 발생하여 Pod가 계속 죽는 문제가 있었습니다.
    *   **불필요한 의존성 제거**: 현재 사용하지 않는 기능에 대한 의존성을 제거하여 애플리케이션을 더 가볍고 안정적으로 만들었습니다.
    *   **단계적 개발**: 현재 단계에서는 Core CI/CD 및 환경 분리에 집중하고, Bedrock 기능은 추후 구현하여 점진적으로 통합하기 위함입니다.

### **7단계: AWS Route53 도메인 연결**

*   **적용 내용**: AWS Route53에서 `dev-api.fall-in-jeju.com`과 `api.fall-in-jeju.com` 도메인에 대한 DNS 레코드를 생성하고, Ingress (ALB)의 주소에 연결했습니다.
*   **적용 이유**: 사용자가 웹 브라우저에서 `dev-api.fall-in-jeju.com` 또는 `api.fall-in-jeju.com`을 입력했을 때, EKS 클러스터 내부의 백엔드 애플리케이션으로 트래픽이 정상적으로 전달되도록 하기 위함입니다.

---

## ⛔ 문제 해결 과정 (Troubleshooting Stories)

프로젝트를 진행하면서 수많은 에러와 충돌에 부딪혔고, 하나씩 해결해 나갔습니다. 이 과정도 중요한 학습의 일부입니다.

*   **Windows PowerShell 명령어 호환성 문제**: `mkdir -p`, `base64` 등 Linux 기반 명령어가 PowerShell에서 작동하지 않아, PowerShell에 맞는 명령어로 대체하여 사용했습니다. (`mkdir` 분리, PowerShell 내장 Base64 디코딩 등)
    *   **교훈**: 운영체제 환경에 따라 터미널 명령어가 다를 수 있음을 항상 인지하고 대응해야 합니다.
*   **Git Merge Conflict 대환장 파티**: `dev`와 `main` 브랜치 간의 잦은 병합 충돌(`CONFLICT`)이 발생했습니다. 특히 `k8s-manifests/base/deployment.yml` 같은 핵심 파일에서 이미지 태그 충돌 등이 있었습니다.
    *   **해결**: `git pull`, `git merge`, `git status`를 반복적으로 사용하며 충돌 구간을 수동으로 해결하고, 원하는 코드(예: `latest` 이미지 태그 유지)를 선택했습니다. 때로는 GitHub의 브랜치 보호 규칙으로 인해 `git push --force`가 거부되기도 했으나, 최종적으로는 성공했습니다.
    *   **교훈**: Git 충돌은 개발 과정의 자연스러운 부분입니다. 충돌 해결 방법을 숙지하고, 커밋 메시지를 명확히 작성하며, 주기적으로 동기화하는 습관이 중요합니다.
*   **ArgoCD 애플리케이션 Manifest 경로 오류**: ArgoCD가 GitHub의 `k8s-manifests/overlays/dev` 경로를 찾지 못해 배포에 실패했습니다.
    *   **원인**: 로컬에서 Kustomize 폴더 구조를 만들었지만, GitHub 저장소에 아직 푸시되지 않았기 때문입니다.
    *   **해결**: 변경된 Manifest 파일들을 GitHub에 성공적으로 푸시하여 ArgoCD가 올바른 경로를 참조하도록 했습니다.
*   **Kubernetes `IngressClass` 미발견 오류**: `dev` Ingress에서 `ingressClass 'alb' not found` 에러가 발생했습니다.
    *   **원인**: EKS 클러스터에 `alb`라는 `IngressClass` 리소스 자체가 정의되어 있지 않았기 때문입니다.
    *   **해결**: `k8s-manifests/base/ingress-class.yml` 파일을 생성하여 `alb` IngressClass를 명시적으로 정의하고 클러스터에 배포했습니다.
*   **AWS Load Balancer Controller 설치 및 권한 오류**: ALB가 생성되지 않거나 `vpcID`를 찾지 못하는 에러가 발생했습니다.
    *   **원인**: ALB Controller가 EKS 클러스터에 설치되지 않았거나, AWS 리소스에 접근할 IAM 권한이 없었기 때문입니다. 또한, ALB Controller가 `vpcId`와 `region` 정보를 자동으로 가져오지 못하는 경우가 있었습니다.
    *   **해결**:
        1.  `eksctl utils associate-iam-oidc-provider`로 IAM OIDC Provider를 클러스터와 연동했습니다.
        2.  Helm 차트를 통해 ALB Controller를 ArgoCD 앱으로 배포했습니다.
        3.  ArgoCD의 `aws-lb-controller` 앱 설정에 클러스터의 `vpcId`와 `region`을 명시적으로 추가했습니다.
*   **데이터베이스 연결 및 스키마 오류**: Spring Boot Pod가 DB 연결 문제로 `CrashLoopBackOff` 상태가 되었습니다.
    *   **원인**:
        1.  EKS 워커 노드 보안 그룹이 RDS DB 인스턴스의 보안 그룹에 접근할 수 있도록 허용되지 않았습니다.
        2.  `dev`와 `prod` 환경의 RDS MySQL에 `jeju_dev`, `jeju_prod` 데이터베이스(스키마)가 수동으로 생성되지 않았습니다. (`ddl-auto: validate` 설정은 스키마를 자동으로 만들지 않고 검증만 합니다.)
    *   **해결**:
        1.  RDS 보안 그룹의 인바운드 규칙에 EKS 워커 노드의 보안 그룹을 추가했습니다.
        2.  각 RDS 인스턴스에 필요한 데이터베이스 스키마를 수동으로 생성했습니다.
*   **Bedrock 관련 `BeanCreationException` 및 플레이스홀더 오류**: 애플리케이션 시작 시 `Could not resolve placeholder 'aws.bedrock.region'` 에러가 발생하여 Pod가 죽는 문제가 있었습니다.
    *   **원인**: `application-*.yml` 파일들과 `AwsProperties.java`, `AwsProdConfig.java` 파일에 Bedrock 관련 설정(특히 `@Value` 어노테이션이 붙은 필드)이 주석 처리되었더라도, Spring이 여전히 해당 플레이스홀더 값을 찾으려고 시도했기 때문입니다.
    *   **해결**: 관련된 `@Value` 필드나 빈 정의를 **완전히 삭제**하여 Spring이 해당 플레이스홀더를 찾으려 시도하지 않도록 했습니다. 이는 현재 Bedrock 기능을 사용하지 않으므로 가장 깔끔한 해결책이었습니다.
    *   **교훈**: 사용하지 않는 `@Value` 어노테이션이나 빈 정의는 주석 처리만으로는 충분하지 않을 수 있으며, 완전히 제거하는 것이 안전합니다.

---

## 🚀 다음 단계: 앞으로 무엇을 더 할 수 있을까요? (미래 가이드라인)

백엔드 CI/CD 파이프라인과 Dev/Prod 환경 분리는 성공적으로 구축되었습니다. 이제 이 기반 위에 더 많은 기능을 추가하고 시스템을 고도화할 수 있습니다.

### **1. 프론트엔드 CI/CD 구축**
*   **목표**: 프론트엔드 코드(React, Vue, Angular 등)를 GitHub에 푸시하면, 자동으로 빌드하여 AWS S3에 배포하고, CloudFront를 통해 전 세계 사용자에게 빠르게 서비스합니다.
*   **필요한 작업**:
    *   **AWS S3**: 정적 웹사이트 호스팅을 위한 S3 버킷 생성 (Dev/Prod 분리).
    *   **AWS CloudFront**: S3 버킷을 원본으로 하는 CloudFront 배포 생성 (캐싱, HTTPS 적용).
    *   **AWS CodeBuild / CodePipeline**: 프론트엔드 코드를 빌드하고 S3에 배포하는 CI/CD 파이프라인 구성.
    *   **Route53**: `dev-fall-in-jeju.com` 및 `fall-in-jeju.com` 도메인을 CloudFront 배포에 연결.

### **2. S3 이미지 업로드 기능 구현**
*   **목표**: 백엔드 애플리케이션에서 AWS S3에 이미지를 업로드하고 관리하는 기능을 추가합니다.
*   **필요한 작업**:
    *   **S3 버킷 생성**: 이미지 저장을 위한 S3 버킷 생성.
    *   **IAM 권한 설정**: 백엔드 Pod가 S3에 접근하고 파일을 업로드할 수 있도록 IAM Role 및 정책 설정. (EKS Service Account와 IAM Role 연동)
    *   **백엔드 코드 구현**: Spring Boot 애플리케이션에 AWS SDK for S3를 사용하여 이미지 업로드 및 관리 로직 구현.

### **3. CloudFront 통합 및 최적화 (백엔드 API 포함)**
*   **목표**: 백엔드 API 트래픽도 CloudFront를 통해 캐싱하고 보안을 강화하여 전반적인 서비스 성능과 안정성을 향상시킵니다.
*   **필요한 작업**:
    *   **CloudFront 원본 그룹 설정**: 백엔드 ALB와 S3 버킷을 포함하는 원본 그룹 설정.
    *   **CloudFront 동작 설정**: API 경로 (`/api/*`)에 대한 캐싱 정책, 요청/응답 헤더 전달 설정, HTTPS 강제 등 상세 설정.
    *   **WAF (Web Application Firewall) 연동**: CloudFront와 AWS WAF를 연동하여 웹 공격으로부터 API를 보호.

### **4. 모니터링 및 로깅 강화**
*   **목표**: 시스템의 상태를 실시간으로 모니터링하고, 문제가 발생했을 때 빠르게 원인을 파악할 수 있도록 로깅 및 알림 시스템을 고도화합니다.
*   **필요한 작업**:
    *   **CloudWatch Metrics 확장**: CPU, 메모리 외에 애플리케이션 내부의 주요 비즈니스 지표(예: API 호출 수, 에러율, 응답 시간)를 커스텀 메트릭으로 수집.
    *   **CloudWatch Logs 개선**: 애플리케이션 내부에서 발생하는 상세 로그(예: 트랜잭션 로그, 사용자 활동 로그)를 구조화하여 수집하고, CloudWatch Logs Insights를 활용한 고급 분석.
    *   **알림 시스템 구축**: 특정 임계값(예: 에러율 5% 이상) 초과 시 Slack, 이메일 등으로 자동 알림 발송.

### **5. 보안 강화**
*   **목표**: 시스템 전체의 보안 수준을 더욱 높여 잠재적인 위협으로부터 서비스를 보호합니다.
*   **필요한 작업**:
    *   **Kubernetes Secret 암호화**: AWS KMS와 같은 서비스를 연동하여 Kubernetes Secret에 저장된 민감 데이터를 실제 암호화합니다.
    *   **IAM Role 최소 권한 원칙 재검토**: 모든 IAM Role(CodeBuild, ALB Controller, EKS Service Account 등)에 부여된 권한이 필요한 최소한의 권한만을 가지도록 주기적으로 검토하고 조정합니다.
    *   **네트워크 보안 강화**: EKS Cluster Security Group, Worker Node Security Group, ALB Security Group, RDS Security Group 간의 통신 규칙을 더욱 세밀하게 조정하여 불필요한 접근을 차단합니다.

### **6. 고급 배포 전략 도입**
*   **목표**: 서비스 중단 없이 안전하게 새로운 버전을 배포하고, 문제가 발생했을 때 사용자에게 미치는 영향을 최소화합니다.
*   **필요한 작업**:
    *   **카나리(Canary) 배포**: 새로운 버전의 애플리케이션을 소수의 사용자에게만 먼저 배포하여 테스트하고, 문제가 없으면 점진적으로 전체 사용자에게 확장하는 전략.
    *   **블루/그린(Blue/Green) 배포**: 현재 운영 중인 버전(Blue)과 동일한 새로운 버전(Green)을 배포한 후, 트래픽을 한 번에 Green으로 전환하는 전략.

---

이 가이드가 '4-in-Jeju' 백엔드 프로젝트의 여정을 이해하는 데 큰 도움이 되었기를 바랍니다. 한 단계 한 단계 나아가면서 궁금한 점이 생긴다면 언제든지 질문해주세요! 우리는 계속 함께 배울 수 있습니다. 화이팅! 💪

